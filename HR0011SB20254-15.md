# HR0011SB20254-15: Unbiased Behavioral Discovery Platforms

**Topic:** Unbiased Behavioral Discovery Platforms  
**Agency:** DoD SBIR 2025.4  
**Branch:** DARPA  
**Opens:** 10/08/2025  
**Closes:** 11/05/2025  
**Status:** Pre-Release  
**Type:** Phase I or Direct to Phase II (DP2)

## Technology Areas
- Chem Bio Defense

## Modernization Priorities
- Biotechnology

## Keywords
Animal Behavior, Biotechnology, Preclinical studies, Animal Models, Medical Countermeasures, Deep Learning, Machine Vision

---

## Analysis: What You'd Actually Build

### The Core Problem
The DoD needs to develop medical countermeasures (MCMs) against chemical, biological, radiological, and nuclear (CBRN) threats. Since you can't ethically test nerve agents or bioweapons on humans, they rely on animal models. But current behavioral testing is:
- **Insensitive** - requires high doses to see effects
- **Subjective** - depends on human observers
- **Variable** - different operators get different results
- **Slow** - manual observation is time-consuming

This means they can't detect threats early or rapidly test countermeasures.

### What You'd Build

You'd develop an **AI-powered automated animal behavior analysis system** that can detect subtle behavioral changes invisible to human observers. Think of it as "computer vision + deep learning for detecting poisoning/disease in lab animals."

#### Core System Components:

1. **Multi-Modal Sensing**
   - High-resolution video cameras (multiple angles)
   - Pose estimation (tracking body parts, limbs, head, tail)
   - Facial expression analysis (orofacial recognition)
   - Audio analysis (vocalizations, breathing patterns)
   - Potentially thermal imaging

2. **AI/ML Pipeline**
   - Deep learning models (likely based on DeepLabCut, SLEAP, or similar)
   - Unsupervised behavior discovery (finding patterns humans never noticed)
   - Real-time processing and classification
   - Dose-response sensitivity analysis

3. **Automated Analysis**
   - No human annotation required
   - Discovers novel behavioral markers
   - Quantifies subtle changes (tremors, gait changes, social behavior)
   - Works at subclinical doses (before obvious symptoms)

4. **High-Throughput Capability**
   - Monitor multiple animals simultaneously
   - Minimal handling required
   - Compatible with BSL-3/BSL-4 containment (aerosolized toxins)
   - Works across species (insects to mammals)

### Concrete Use Case Example
**Scenario:** Testing a new nerve agent antidote

**Traditional approach:** Expose mice to nerve agent, wait for seizures/death, test antidote. Requires high doses, many animals die, slow process.

**Your system:** 
1. Expose mice to **subclinical doses** (1/10th the traditional amount)
2. Your cameras capture subtle behavioral changes in first 30 minutes:
   - Slight tremor in left forelimb (2.3 Hz frequency)
   - Reduced grooming behavior (15% decrease)
   - Altered gait pattern (stride length -8%)
   - Facial grimacing (pain response)
3. AI detects these patterns automatically, flags exposed animals
4. Test antidote candidates rapidly on these early markers
5. **Result:** Faster MCM development, fewer animals, lower doses, earlier detection

### Phase Deliverables

#### Phase I (~$200K, 8 months):
**Deliverables:**
- Month 1: Report on architectures, algorithms, learning approaches
- Month 3: Report on training/test datasets, evaluation metrics, initial results
- Month 5: Interim performance report
- Month 8: **Demonstration** - Prototype detecting novel behaviors in one animal model
- Final Report including:
  - Prototype architecture and algorithms
  - Comparison with state-of-the-art behavioral assays
  - Quantification of accuracy, robustness, generalizability
  - User manual/instructions
  - Feasibility analysis for 5 compatibility directions:
    1. Other physiologies (pain, psychiatric, seizure, TBI, etc.)
    2. Aerosolized toxic environments
    3. High-throughput settings
    4. Behavioral barcodes (multi-feature patterns)
    5. Other animal models

**Success Criteria:**
- Match or exceed sensitivity/specificity of state-of-the-art assays
- Demonstrate reproducibility across cohorts
- Show dose-sensitivity
- Achieve TRL 3

#### Phase II (~$1.1M, 24 months):
**Deliverables:**
- Advance prototype to address 2+ compatibility areas
- Month 12: Demonstration with **DARPA-selected** drug or pathogen
- Month 24: Final demonstration with DARPA-selected challenge
- Deliver full-scale prototype for chemical/biodefense testing
- Complete documentation, source code, user manuals
- Achieve TRL 6

**Key Milestones:**
- Multiple animal models or physiologies
- High-throughput capability
- Aerosolized environment compatibility
- Multi-feature behavioral barcodes

#### Phase III (follow-on):
- Transition to chemical/biological defense pipelines
- Commercial applications in drug development
- Preclinical research tools for pharma/biotech

### Key Technical Challenges
- **Unsupervised behavior discovery** - Finding patterns without knowing what to look for
- **Subclinical sensitivity** - Detecting effects at very low doses
- **Generalization** - Working across different threats, species, environments
- **BSL-3/BSL-4 compatibility** - Operating in high-containment facilities
- **Real-time processing** - Analyzing video streams with low latency
- **Reproducibility** - Consistent results across studies and facilities
- **No surgery allowed** - Must be completely non-invasive

### Dual Use Applications
Huge commercial potential in pharmaceutical and biotech:
- **Drug Development:** Preclinical efficacy and toxicity testing
- **Pain Research:** Automated pain assessment in animal models
- **Neuroscience:** Psychiatric disorder models, TBI research
- **Veterinary Medicine:** Animal health monitoring
- **Academic Research:** Behavioral neuroscience, genetics
- **Regulatory Testing:** Standardized, objective behavioral assessments

**Market:** Multi-billion dollar preclinical research market

---

## Why This Fits Your Criteria

This is a **moderate fit** with some concerns:
- ✅ **AI/ML** - Core deep learning and computer vision
- ✅ **Machine Vision** - Multi-camera pose estimation and tracking
- ✅ **Software Engineering** - Real-time processing pipelines
- ✅ **Databases** - Managing behavioral data and training sets
- ⚠️ **Animal Research** - Requires access to animal facilities and expertise
- ⚠️ **Biology/Toxicology** - Need domain expertise or partners
- ⚠️ **Hardware Integration** - Camera systems, containment compatibility

**Recommendation:** Strong technical fit for AI/ML skills, but requires partnerships with animal research facilities and toxicology experts. Consider teaming with a university or research institute.

---

## Topic Details from Solicitation

### Objective
The DoD seeks to develop unguided behavioral discovery technologies to accelerate detection and medical countermeasure development against current and future threats. These platforms will enable:
- Quantification of novel behaviors in pre-clinical animal models that are more sensitive than state-of-the-art
- High-throughput evaluation of intervention efficacy in animal models with high translational value

### Description
Animal model behavioral evaluations remain un-modernized, insensitive, and prone to significant variability. Threat agent doses required to elicit observable responses are much higher than effective threat doses to warfighters. Recent innovations in machine learning have enabled sensitive detection of animal behaviors beyond what historical "gold standard" assays can accomplish.

### Physiologies of Interest
- Toxidromes
- Neuropsychiatric disorders
- Seizure characterization
- Traumatic brain injury
- Neurodegenerative disorders
- Sleep state

### Requirements
The proposed solution must:
- Use non-invasive measurements (no surgery)
- Not require human annotation of behaviors
- Identify behavioral responses not previously quantified
- Outperform state-of-the-art behavioral assays
- Demonstrate increased sensitivity to subclinical doses or presymptomatic disease states
- Integrate multiple behavioral feature spaces (movement, facial, auditory)
- Minimize animal handling and training

### Direct-to-Phase-II Option
DP2 proposers must provide:
- Technical documentation of automated novel behavior detection
- Peer-reviewed publications, pre-prints, patents, or proprietary reports
- Sensitivity/specificity matching or surpassing state-of-the-art
- Phase I-equivalent final report content

---

## References

1. Office of the Commissioner. "Animal rule information." U.S. FDA, 2024. http://fda.gov/emergency-preparedness-and-response/preparedness-research/animal-rule-information

2. Zhang Z, et al. "Automated preclinical detection of mechanical pain hypersensitivity and analgesia." Pain. 2022;163(12):2326-2336.

3. Mathis, A., et al. "DeepLabCut: markerless pose estimation of user-defined body parts with deep learning." Nat Neurosci 21, 1281–1289 (2018).

4. Pereira, T.D., et al. "SLEAP: A deep learning system for multi-animal pose tracking." Nat Methods 19, 486–495 (2022).

5. Guo, C., et al. "A Survey on AI-Driven Mouse Behavior Analysis Applications and Solutions." Bioengineering 2024, 11, 1121.

---

## Important Notes

### Phase I or DP2
- Can apply for Phase I (8 months, ~$200K)
- OR Direct-to-Phase-II if you have prior feasibility work
- DP2 requires demonstrated prior results

### Animal Research Requirements
- Need access to animal research facilities
- Must comply with IACUC protocols
- Experience with animal models essential
- Toxicology/pharmacology expertise helpful

### Technical Readiness
- Phase I: TRL 3
- Phase II: TRL 6
- Must demonstrate with DARPA-selected challenges in Phase II

